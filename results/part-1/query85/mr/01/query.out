
Logging initialized using configuration in jar:file:/home/ubuntu/software/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties
Hive history file=/tmp/ubuntu/hive_job_log_fee0c3dc-4281-4e69-90fb-16c1c6e97268_1543683987.txt
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 0.95 seconds
Query ID = ubuntu_20160924204627_72d8e01a-cd66-42a0-8132-8c913671cf49
Total jobs = 16
Stage-1 is selected by condition resolver.
Launching Job 1 out of 16
Number of reduce tasks not specified. Estimated from input data size: 32
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0392, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0392/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0392
Hadoop job information for Stage-1: number of mappers: 30; number of reducers: 32
2016-09-24 20:46:41,907 Stage-1 map = 0%,  reduce = 0%
2016-09-24 20:46:53,480 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 16.46 sec
2016-09-24 20:46:54,576 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 68.6 sec
2016-09-24 20:46:59,788 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 88.53 sec
2016-09-24 20:47:00,832 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 99.09 sec
2016-09-24 20:47:02,922 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 102.42 sec
2016-09-24 20:47:03,965 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 112.33 sec
2016-09-24 20:47:09,159 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 132.95 sec
2016-09-24 20:47:10,227 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 153.41 sec
2016-09-24 20:47:11,271 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 160.72 sec
2016-09-24 20:47:12,323 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 171.3 sec
2016-09-24 20:47:13,384 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 182.99 sec
2016-09-24 20:47:14,439 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 187.14 sec
2016-09-24 20:47:15,512 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 189.36 sec
2016-09-24 20:47:16,565 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 193.03 sec
2016-09-24 20:47:21,775 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 215.19 sec
2016-09-24 20:47:23,860 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 243.55 sec
2016-09-24 20:47:24,928 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 252.47 sec
2016-09-24 20:47:25,969 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 264.18 sec
2016-09-24 20:47:27,008 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 273.6 sec
2016-09-24 20:47:28,048 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 277.3 sec
2016-09-24 20:47:29,088 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 283.84 sec
2016-09-24 20:47:30,137 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 290.3 sec
2016-09-24 20:47:31,180 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 295.14 sec
2016-09-24 20:47:32,229 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 299.78 sec
2016-09-24 20:47:33,273 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 305.46 sec
2016-09-24 20:47:34,324 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 312.4 sec
2016-09-24 20:47:35,370 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 315.93 sec
2016-09-24 20:47:36,410 Stage-1 map = 90%,  reduce = 0%, Cumulative CPU 320.88 sec
2016-09-24 20:47:37,453 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 327.96 sec
2016-09-24 20:47:38,509 Stage-1 map = 95%,  reduce = 0%, Cumulative CPU 329.52 sec
2016-09-24 20:47:39,550 Stage-1 map = 96%,  reduce = 0%, Cumulative CPU 330.99 sec
2016-09-24 20:47:40,594 Stage-1 map = 98%,  reduce = 0%, Cumulative CPU 334.67 sec
2016-09-24 20:47:41,647 Stage-1 map = 99%,  reduce = 0%, Cumulative CPU 335.97 sec
2016-09-24 20:47:42,683 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 338.36 sec
2016-09-24 20:47:54,157 Stage-1 map = 100%,  reduce = 12%, Cumulative CPU 362.58 sec
2016-09-24 20:47:55,251 Stage-1 map = 100%,  reduce = 21%, Cumulative CPU 383.01 sec
2016-09-24 20:47:56,297 Stage-1 map = 100%,  reduce = 24%, Cumulative CPU 390.47 sec
2016-09-24 20:47:57,370 Stage-1 map = 100%,  reduce = 37%, Cumulative CPU 416.52 sec
2016-09-24 20:47:58,456 Stage-1 map = 100%,  reduce = 47%, Cumulative CPU 435.62 sec
2016-09-24 20:47:59,517 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 442.39 sec
2016-09-24 20:48:04,775 Stage-1 map = 100%,  reduce = 53%, Cumulative CPU 448.65 sec
2016-09-24 20:48:05,823 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 466.94 sec
2016-09-24 20:48:06,866 Stage-1 map = 100%,  reduce = 71%, Cumulative CPU 486.11 sec
2016-09-24 20:48:07,904 Stage-1 map = 100%,  reduce = 81%, Cumulative CPU 506.2 sec
2016-09-24 20:48:08,941 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 530.81 sec
2016-09-24 20:48:09,976 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 536.81 sec
2016-09-24 20:48:11,011 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 543.38 sec
MapReduce Total cumulative CPU time: 9 minutes 3 seconds 380 msec
Ended Job = job_1474660851143_0392
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924204627_72d8e01a-cd66-42a0-8132-8c913671cf49.log
2016-09-24 20:48:14	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 20:48:16	Dump the side-table for tag: 1 with group count: 876 into file: file:/tmp/ubuntu/fee0c3dc-4281-4e69-90fb-16c1c6e97268/hive_2016-09-24_20-46-27_944_2219290439388143082-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable
2016-09-24 20:48:16	Uploaded 1 File to: file:/tmp/ubuntu/fee0c3dc-4281-4e69-90fb-16c1c6e97268/hive_2016-09-24_20-46-27_944_2219290439388143082-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable (17481 bytes)
2016-09-24 20:48:16	End of local task; Time Taken: 1.261 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 2 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0393, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0393/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0393
Hadoop job information for Stage-30: number of mappers: 4; number of reducers: 0
2016-09-24 20:48:21,625 Stage-30 map = 0%,  reduce = 0%
2016-09-24 20:48:34,032 Stage-30 map = 38%,  reduce = 0%, Cumulative CPU 23.18 sec
2016-09-24 20:48:37,133 Stage-30 map = 91%,  reduce = 0%, Cumulative CPU 34.75 sec
2016-09-24 20:48:38,167 Stage-30 map = 100%,  reduce = 0%, Cumulative CPU 36.58 sec
MapReduce Total cumulative CPU time: 36 seconds 580 msec
Ended Job = job_1474660851143_0393
Stage-41 is filtered out by condition resolver.
Stage-42 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Launching Job 3 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0394, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0394/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0394
Hadoop job information for Stage-3: number of mappers: 5; number of reducers: 2
2016-09-24 20:48:45,202 Stage-3 map = 0%,  reduce = 0%
2016-09-24 20:48:55,509 Stage-3 map = 20%,  reduce = 0%, Cumulative CPU 4.74 sec
2016-09-24 20:48:57,578 Stage-3 map = 59%,  reduce = 0%, Cumulative CPU 21.45 sec
2016-09-24 20:48:58,616 Stage-3 map = 66%,  reduce = 0%, Cumulative CPU 22.44 sec
2016-09-24 20:48:59,671 Stage-3 map = 80%,  reduce = 0%, Cumulative CPU 25.47 sec
2016-09-24 20:49:00,707 Stage-3 map = 83%,  reduce = 0%, Cumulative CPU 28.47 sec
2016-09-24 20:49:03,806 Stage-3 map = 87%,  reduce = 0%, Cumulative CPU 31.66 sec
2016-09-24 20:49:06,904 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 33.77 sec
2016-09-24 20:49:10,007 Stage-3 map = 93%,  reduce = 0%, Cumulative CPU 36.9 sec
2016-09-24 20:49:17,227 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 44.15 sec
2016-09-24 20:49:27,554 Stage-3 map = 100%,  reduce = 36%, Cumulative CPU 51.38 sec
2016-09-24 20:49:28,591 Stage-3 map = 100%,  reduce = 72%, Cumulative CPU 58.51 sec
2016-09-24 20:49:30,658 Stage-3 map = 100%,  reduce = 80%, Cumulative CPU 65.0 sec
2016-09-24 20:49:33,766 Stage-3 map = 100%,  reduce = 87%, Cumulative CPU 71.39 sec
2016-09-24 20:49:36,860 Stage-3 map = 100%,  reduce = 95%, Cumulative CPU 77.85 sec
2016-09-24 20:49:38,927 Stage-3 map = 100%,  reduce = 97%, Cumulative CPU 79.6 sec
2016-09-24 20:49:39,960 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 82.32 sec
MapReduce Total cumulative CPU time: 1 minutes 22 seconds 320 msec
Ended Job = job_1474660851143_0394
Stage-39 is filtered out by condition resolver.
Stage-40 is filtered out by condition resolver.
Stage-4 is selected by condition resolver.
Launching Job 4 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0395, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0395/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0395
Hadoop job information for Stage-4: number of mappers: 6; number of reducers: 2
2016-09-24 20:49:45,988 Stage-4 map = 0%,  reduce = 0%
2016-09-24 20:49:55,306 Stage-4 map = 17%,  reduce = 0%, Cumulative CPU 4.45 sec
2016-09-24 20:49:57,369 Stage-4 map = 33%,  reduce = 0%, Cumulative CPU 16.22 sec
2016-09-24 20:49:58,405 Stage-4 map = 67%,  reduce = 0%, Cumulative CPU 32.47 sec
2016-09-24 20:50:03,551 Stage-4 map = 78%,  reduce = 0%, Cumulative CPU 42.12 sec
2016-09-24 20:50:04,583 Stage-4 map = 94%,  reduce = 0%, Cumulative CPU 47.02 sec
2016-09-24 20:50:06,645 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 48.94 sec
2016-09-24 20:50:17,988 Stage-4 map = 100%,  reduce = 71%, Cumulative CPU 63.9 sec
2016-09-24 20:50:21,078 Stage-4 map = 100%,  reduce = 78%, Cumulative CPU 70.45 sec
2016-09-24 20:50:24,176 Stage-4 map = 100%,  reduce = 85%, Cumulative CPU 76.85 sec
2016-09-24 20:50:26,239 Stage-4 map = 100%,  reduce = 88%, Cumulative CPU 80.02 sec
2016-09-24 20:50:27,273 Stage-4 map = 100%,  reduce = 91%, Cumulative CPU 83.21 sec
2016-09-24 20:50:29,337 Stage-4 map = 100%,  reduce = 95%, Cumulative CPU 86.51 sec
2016-09-24 20:50:30,386 Stage-4 map = 100%,  reduce = 98%, Cumulative CPU 90.28 sec
2016-09-24 20:50:31,418 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 92.1 sec
MapReduce Total cumulative CPU time: 1 minutes 32 seconds 100 msec
Ended Job = job_1474660851143_0395
Stage-37 is filtered out by condition resolver.
Stage-38 is filtered out by condition resolver.
Stage-5 is selected by condition resolver.
Launching Job 5 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0396, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0396/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0396
Hadoop job information for Stage-5: number of mappers: 3; number of reducers: 2
2016-09-24 20:50:38,309 Stage-5 map = 0%,  reduce = 0%
2016-09-24 20:50:48,561 Stage-5 map = 33%,  reduce = 0%, Cumulative CPU 4.18 sec
2016-09-24 20:50:55,727 Stage-5 map = 68%,  reduce = 0%, Cumulative CPU 30.05 sec
2016-09-24 20:50:58,803 Stage-5 map = 78%,  reduce = 0%, Cumulative CPU 36.43 sec
2016-09-24 20:51:00,864 Stage-5 map = 89%,  reduce = 0%, Cumulative CPU 38.36 sec
2016-09-24 20:51:01,894 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 40.65 sec
2016-09-24 20:51:12,150 Stage-5 map = 100%,  reduce = 36%, Cumulative CPU 47.8 sec
2016-09-24 20:51:13,177 Stage-5 map = 100%,  reduce = 72%, Cumulative CPU 55.33 sec
2016-09-24 20:51:15,230 Stage-5 map = 100%,  reduce = 78%, Cumulative CPU 61.88 sec
2016-09-24 20:51:18,308 Stage-5 map = 100%,  reduce = 85%, Cumulative CPU 68.35 sec
2016-09-24 20:51:21,382 Stage-5 map = 100%,  reduce = 92%, Cumulative CPU 74.92 sec
2016-09-24 20:51:24,464 Stage-5 map = 100%,  reduce = 98%, Cumulative CPU 81.38 sec
2016-09-24 20:51:25,492 Stage-5 map = 100%,  reduce = 99%, Cumulative CPU 82.15 sec
2016-09-24 20:51:27,543 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 83.53 sec
MapReduce Total cumulative CPU time: 1 minutes 23 seconds 530 msec
Ended Job = job_1474660851143_0396
Stage-35 is selected by condition resolver.
Stage-36 is filtered out by condition resolver.
Stage-6 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924204627_72d8e01a-cd66-42a0-8132-8c913671cf49.log
2016-09-24 20:51:31	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 20:51:33	Dump the side-table for tag: 1 with group count: 365 into file: file:/tmp/ubuntu/fee0c3dc-4281-4e69-90fb-16c1c6e97268/hive_2016-09-24_20-46-27_944_2219290439388143082-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable
2016-09-24 20:51:33	Uploaded 1 File to: file:/tmp/ubuntu/fee0c3dc-4281-4e69-90fb-16c1c6e97268/hive_2016-09-24_20-46-27_944_2219290439388143082-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable (7963 bytes)
2016-09-24 20:51:33	End of local task; Time Taken: 2.047 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 7 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0397, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0397/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0397
Hadoop job information for Stage-18: number of mappers: 2; number of reducers: 0
2016-09-24 20:51:38,831 Stage-18 map = 0%,  reduce = 0%
2016-09-24 20:51:52,239 Stage-18 map = 64%,  reduce = 0%, Cumulative CPU 20.97 sec
2016-09-24 20:51:53,271 Stage-18 map = 100%,  reduce = 0%, Cumulative CPU 21.51 sec
MapReduce Total cumulative CPU time: 21 seconds 510 msec
Ended Job = job_1474660851143_0397
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924204627_72d8e01a-cd66-42a0-8132-8c913671cf49.log
2016-09-24 20:51:56	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 20:51:58	Dump the side-table for tag: 1 with group count: 39 into file: file:/tmp/ubuntu/fee0c3dc-4281-4e69-90fb-16c1c6e97268/hive_2016-09-24_20-46-27_944_2219290439388143082-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable
2016-09-24 20:51:58	Uploaded 1 File to: file:/tmp/ubuntu/fee0c3dc-4281-4e69-90fb-16c1c6e97268/hive_2016-09-24_20-46-27_944_2219290439388143082-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (1662 bytes)
2016-09-24 20:51:58	End of local task; Time Taken: 1.219 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 8 out of 16
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0398, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0398/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0398
Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1
2016-09-24 20:52:03,744 Stage-8 map = 0%,  reduce = 0%
2016-09-24 20:52:14,020 Stage-8 map = 33%,  reduce = 0%, Cumulative CPU 7.22 sec
2016-09-24 20:52:15,052 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 8.28 sec
2016-09-24 20:52:21,229 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 9.98 sec
MapReduce Total cumulative CPU time: 9 seconds 980 msec
Ended Job = job_1474660851143_0398
Launching Job 9 out of 16
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0399, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0399/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0399
Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 1
2016-09-24 20:52:28,182 Stage-9 map = 0%,  reduce = 0%
2016-09-24 20:52:33,327 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 1.16 sec
2016-09-24 20:52:38,469 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 2.42 sec
MapReduce Total cumulative CPU time: 2 seconds 420 msec
Ended Job = job_1474660851143_0399
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 30  Reduce: 32   Cumulative CPU: 543.38 sec   HDFS Read: 8124263543 HDFS Write: 226967742 SUCCESS
Stage-Stage-30: Map: 4   Cumulative CPU: 36.58 sec   HDFS Read: 227005674 HDFS Write: 235481531 SUCCESS
Stage-Stage-3: Map: 5  Reduce: 2   Cumulative CPU: 82.32 sec   HDFS Read: 316193649 HDFS Write: 293830082 SUCCESS
Stage-Stage-4: Map: 6  Reduce: 2   Cumulative CPU: 92.1 sec   HDFS Read: 374559476 HDFS Write: 348836292 SUCCESS
Stage-Stage-5: Map: 3  Reduce: 2   Cumulative CPU: 83.53 sec   HDFS Read: 391387383 HDFS Write: 419920333 SUCCESS
Stage-Stage-18: Map: 2   Cumulative CPU: 21.51 sec   HDFS Read: 419946201 HDFS Write: 85556487 SUCCESS
Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 9.98 sec   HDFS Read: 85590089 HDFS Write: 1858 SUCCESS
Stage-Stage-9: Map: 1  Reduce: 1   Cumulative CPU: 2.42 sec   HDFS Read: 7071 HDFS Write: 1783 SUCCESS
Total MapReduce CPU Time Spent: 14 minutes 31 seconds 820 msec
OK
Did not fit	36.4	922.3180053710937	44.14999961853027
Did not like the col	7.0	65.66000366210938	52.52000045776367
Did not like the mak	12.0	359.4599914550781	34.9900016784668
Did not like the mod	4.5	96.23500061035156	18.535000205039978
Found a better exten	5.0	65.47000122070312	41.73500061035156
Found a better price	21.5	365.5500011444092	44.73249959945679
Gift exchange	15.5	502.5549907684326	48.635000228881836
No service location 	18.0	670.0650100708008	32.06499934196472
Not working any more	22.0	90.98999977111816	20.105000019073486
Package was damaged	19.0	941.0019750595093	31.7440003156662
Parts missing	14.333333333333334	213.90000025431314	57.020002365112305
Stopped working	27.0	452.43249130249023	70.0649995803833
Wrong size	23.5	431.12999725341797	65.73999786376953
duplicate purchase	18.0	0.0	5.519999980926514
it is a girl	10.5	474.72498321533203	29.644999027252197
its is a boy	27.5	196.35500717163086	26.50499999523163
reason 24	9.75	172.76999378204346	65.16749954223633
reason 25	9.0	259.3500061035156	52.0099983215332
reason 26	5.0	248.11000061035156	74.68000030517578
reason 27	25.666666666666668	467.3833363850911	38.336666107177734
reason 28	42.0	497.6000061035156	64.03499984741211
reason 29	22.0	374.82666810353595	44.30666542053223
reason 31	36.25	760.8725032806396	54.20750141143799
reason 32	44.0	92.88000297546387	75.44499969482422
reason 33	9.0	180.9300038019816	45.070000330607094
reason 34	31.0	263.83998918533325	33.27000069618225
reason 35	6.0	558.7899780273438	70.2300033569336
reason 36	14.0	407.8599853515625	67.08999633789062
reason 37	24.0	526.3600006103516	57.30000114440918
reason 38	9.0	146.94749927520752	21.157500505447388
reason 39	52.5	675.9999961853027	43.98499870300293
unauthoized purchase	37.0	761.5599975585938	43.720001220703125
Time taken: 372.674 seconds, Fetched: 32 row(s)
Query 85: Total Execution Time = 381 seconds

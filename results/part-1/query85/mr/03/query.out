
Logging initialized using configuration in jar:file:/home/ubuntu/software/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties
Hive history file=/tmp/ubuntu/hive_job_log_cb4045a9-a22f-409c-badd-da6f2341b370_1193842046.txt
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 0.969 seconds
Query ID = ubuntu_20160924211953_75fabfff-bc0b-4098-b5a5-3807dcbfc42a
Total jobs = 16
Stage-1 is selected by condition resolver.
Launching Job 1 out of 16
Number of reduce tasks not specified. Estimated from input data size: 32
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0410, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0410/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0410
Hadoop job information for Stage-1: number of mappers: 30; number of reducers: 32
2016-09-24 21:20:06,197 Stage-1 map = 0%,  reduce = 0%
2016-09-24 21:20:18,813 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 32.43 sec
2016-09-24 21:20:19,865 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 66.72 sec
2016-09-24 21:20:24,013 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 86.6 sec
2016-09-24 21:20:25,058 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 90.74 sec
2016-09-24 21:20:26,096 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 97.94 sec
2016-09-24 21:20:27,136 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 101.31 sec
2016-09-24 21:20:28,182 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 104.94 sec
2016-09-24 21:20:29,227 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 112.39 sec
2016-09-24 21:20:33,362 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 132.59 sec
2016-09-24 21:20:34,420 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 139.7 sec
2016-09-24 21:20:35,465 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 149.89 sec
2016-09-24 21:20:36,518 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 159.59 sec
2016-09-24 21:20:37,578 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 182.44 sec
2016-09-24 21:20:38,674 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 185.9 sec
2016-09-24 21:20:39,737 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 190.48 sec
2016-09-24 21:20:40,789 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 192.4 sec
2016-09-24 21:20:45,984 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 200.84 sec
2016-09-24 21:20:48,060 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 237.1 sec
2016-09-24 21:20:49,109 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 247.45 sec
2016-09-24 21:20:50,150 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 257.81 sec
2016-09-24 21:20:51,210 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 266.13 sec
2016-09-24 21:20:52,263 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 272.62 sec
2016-09-24 21:20:53,302 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 281.41 sec
2016-09-24 21:20:54,346 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 290.61 sec
2016-09-24 21:20:55,385 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 292.03 sec
2016-09-24 21:20:56,430 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 297.78 sec
2016-09-24 21:20:57,502 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 305.08 sec
2016-09-24 21:20:58,538 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 308.69 sec
2016-09-24 21:20:59,597 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 312.17 sec
2016-09-24 21:21:00,634 Stage-1 map = 89%,  reduce = 0%, Cumulative CPU 319.34 sec
2016-09-24 21:21:01,696 Stage-1 map = 93%,  reduce = 0%, Cumulative CPU 323.28 sec
2016-09-24 21:21:02,733 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 327.21 sec
2016-09-24 21:21:03,766 Stage-1 map = 97%,  reduce = 0%, Cumulative CPU 333.68 sec
2016-09-24 21:21:04,800 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 338.17 sec
2016-09-24 21:21:15,182 Stage-1 map = 100%,  reduce = 6%, Cumulative CPU 350.94 sec
2016-09-24 21:21:16,270 Stage-1 map = 100%,  reduce = 13%, Cumulative CPU 364.74 sec
2016-09-24 21:21:17,342 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 383.97 sec
2016-09-24 21:21:18,390 Stage-1 map = 100%,  reduce = 34%, Cumulative CPU 407.89 sec
2016-09-24 21:21:19,450 Stage-1 map = 100%,  reduce = 47%, Cumulative CPU 433.76 sec
2016-09-24 21:21:20,491 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 440.88 sec
2016-09-24 21:21:26,756 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 466.11 sec
2016-09-24 21:21:27,804 Stage-1 map = 100%,  reduce = 65%, Cumulative CPU 472.58 sec
2016-09-24 21:21:28,846 Stage-1 map = 100%,  reduce = 69%, Cumulative CPU 479.25 sec
2016-09-24 21:21:29,895 Stage-1 map = 100%,  reduce = 84%, Cumulative CPU 509.75 sec
2016-09-24 21:21:30,928 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 541.76 sec
MapReduce Total cumulative CPU time: 9 minutes 1 seconds 760 msec
Ended Job = job_1474660851143_0410
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924211953_75fabfff-bc0b-4098-b5a5-3807dcbfc42a.log
2016-09-24 21:21:35	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:21:37	Dump the side-table for tag: 1 with group count: 876 into file: file:/tmp/ubuntu/cb4045a9-a22f-409c-badd-da6f2341b370/hive_2016-09-24_21-19-53_325_394320563611715555-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable
2016-09-24 21:21:37	Uploaded 1 File to: file:/tmp/ubuntu/cb4045a9-a22f-409c-badd-da6f2341b370/hive_2016-09-24_21-19-53_325_394320563611715555-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable (17481 bytes)
2016-09-24 21:21:37	End of local task; Time Taken: 1.237 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 2 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0411, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0411/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0411
Hadoop job information for Stage-30: number of mappers: 4; number of reducers: 0
2016-09-24 21:21:42,895 Stage-30 map = 0%,  reduce = 0%
2016-09-24 21:21:56,324 Stage-30 map = 44%,  reduce = 0%, Cumulative CPU 23.31 sec
2016-09-24 21:21:59,424 Stage-30 map = 97%,  reduce = 0%, Cumulative CPU 34.92 sec
2016-09-24 21:22:00,457 Stage-30 map = 100%,  reduce = 0%, Cumulative CPU 35.48 sec
MapReduce Total cumulative CPU time: 35 seconds 480 msec
Ended Job = job_1474660851143_0411
Stage-41 is filtered out by condition resolver.
Stage-42 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Launching Job 3 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0412, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0412/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0412
Hadoop job information for Stage-3: number of mappers: 5; number of reducers: 2
2016-09-24 21:22:06,389 Stage-3 map = 0%,  reduce = 0%
2016-09-24 21:22:15,644 Stage-3 map = 20%,  reduce = 0%, Cumulative CPU 4.32 sec
2016-09-24 21:22:18,737 Stage-3 map = 53%,  reduce = 0%, Cumulative CPU 14.65 sec
2016-09-24 21:22:19,771 Stage-3 map = 72%,  reduce = 0%, Cumulative CPU 23.52 sec
2016-09-24 21:22:21,833 Stage-3 map = 83%,  reduce = 0%, Cumulative CPU 25.43 sec
2016-09-24 21:22:24,925 Stage-3 map = 87%,  reduce = 0%, Cumulative CPU 31.69 sec
2016-09-24 21:22:28,018 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 34.75 sec
2016-09-24 21:22:31,111 Stage-3 map = 93%,  reduce = 0%, Cumulative CPU 37.95 sec
2016-09-24 21:22:37,295 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 43.47 sec
2016-09-24 21:22:47,593 Stage-3 map = 100%,  reduce = 72%, Cumulative CPU 58.29 sec
2016-09-24 21:22:50,686 Stage-3 map = 100%,  reduce = 79%, Cumulative CPU 64.72 sec
2016-09-24 21:22:53,775 Stage-3 map = 100%,  reduce = 87%, Cumulative CPU 71.02 sec
2016-09-24 21:22:56,894 Stage-3 map = 100%,  reduce = 94%, Cumulative CPU 77.4 sec
2016-09-24 21:22:59,994 Stage-3 map = 100%,  reduce = 99%, Cumulative CPU 81.9 sec
2016-09-24 21:23:01,026 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 83.14 sec
MapReduce Total cumulative CPU time: 1 minutes 23 seconds 140 msec
Ended Job = job_1474660851143_0412
Stage-39 is filtered out by condition resolver.
Stage-40 is filtered out by condition resolver.
Stage-4 is selected by condition resolver.
Launching Job 4 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0413, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0413/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0413
Hadoop job information for Stage-4: number of mappers: 6; number of reducers: 2
2016-09-24 21:23:07,175 Stage-4 map = 0%,  reduce = 0%
2016-09-24 21:23:16,468 Stage-4 map = 17%,  reduce = 0%, Cumulative CPU 4.51 sec
2016-09-24 21:23:18,538 Stage-4 map = 67%,  reduce = 0%, Cumulative CPU 25.83 sec
2016-09-24 21:23:24,727 Stage-4 map = 78%,  reduce = 0%, Cumulative CPU 41.02 sec
2016-09-24 21:23:25,764 Stage-4 map = 88%,  reduce = 0%, Cumulative CPU 44.31 sec
2016-09-24 21:23:26,798 Stage-4 map = 93%,  reduce = 0%, Cumulative CPU 46.39 sec
2016-09-24 21:23:28,862 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 49.26 sec
2016-09-24 21:23:39,200 Stage-4 map = 100%,  reduce = 70%, Cumulative CPU 63.16 sec
2016-09-24 21:23:42,305 Stage-4 map = 100%,  reduce = 76%, Cumulative CPU 69.68 sec
2016-09-24 21:23:45,403 Stage-4 map = 100%,  reduce = 83%, Cumulative CPU 76.11 sec
2016-09-24 21:23:48,502 Stage-4 map = 100%,  reduce = 90%, Cumulative CPU 82.57 sec
2016-09-24 21:23:51,595 Stage-4 map = 100%,  reduce = 96%, Cumulative CPU 89.09 sec
2016-09-24 21:23:53,661 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 92.99 sec
MapReduce Total cumulative CPU time: 1 minutes 32 seconds 990 msec
Ended Job = job_1474660851143_0413
Stage-37 is filtered out by condition resolver.
Stage-38 is filtered out by condition resolver.
Stage-5 is selected by condition resolver.
Launching Job 5 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0414, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0414/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0414
Hadoop job information for Stage-5: number of mappers: 3; number of reducers: 2
2016-09-24 21:24:00,814 Stage-5 map = 0%,  reduce = 0%
2016-09-24 21:24:12,114 Stage-5 map = 33%,  reduce = 0%, Cumulative CPU 17.76 sec
2016-09-24 21:24:18,288 Stage-5 map = 68%,  reduce = 0%, Cumulative CPU 30.5 sec
2016-09-24 21:24:21,377 Stage-5 map = 78%,  reduce = 0%, Cumulative CPU 36.97 sec
2016-09-24 21:24:24,464 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 43.12 sec
2016-09-24 21:24:35,783 Stage-5 map = 100%,  reduce = 35%, Cumulative CPU 49.84 sec
2016-09-24 21:24:36,816 Stage-5 map = 100%,  reduce = 70%, Cumulative CPU 55.74 sec
2016-09-24 21:24:38,880 Stage-5 map = 100%,  reduce = 73%, Cumulative CPU 59.07 sec
2016-09-24 21:24:39,917 Stage-5 map = 100%,  reduce = 77%, Cumulative CPU 62.38 sec
2016-09-24 21:24:40,953 Stage-5 map = 100%,  reduce = 80%, Cumulative CPU 65.59 sec
2016-09-24 21:24:43,017 Stage-5 map = 100%,  reduce = 83%, Cumulative CPU 68.79 sec
2016-09-24 21:24:44,056 Stage-5 map = 100%,  reduce = 86%, Cumulative CPU 72.02 sec
2016-09-24 21:24:46,117 Stage-5 map = 100%,  reduce = 90%, Cumulative CPU 75.35 sec
2016-09-24 21:24:47,148 Stage-5 map = 100%,  reduce = 93%, Cumulative CPU 78.64 sec
2016-09-24 21:24:49,210 Stage-5 map = 100%,  reduce = 96%, Cumulative CPU 81.9 sec
2016-09-24 21:24:50,247 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 85.87 sec
MapReduce Total cumulative CPU time: 1 minutes 25 seconds 870 msec
Ended Job = job_1474660851143_0414
Stage-35 is selected by condition resolver.
Stage-36 is filtered out by condition resolver.
Stage-6 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924211953_75fabfff-bc0b-4098-b5a5-3807dcbfc42a.log
2016-09-24 21:24:54	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:24:55	Dump the side-table for tag: 1 with group count: 365 into file: file:/tmp/ubuntu/cb4045a9-a22f-409c-badd-da6f2341b370/hive_2016-09-24_21-19-53_325_394320563611715555-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable
2016-09-24 21:24:55	Uploaded 1 File to: file:/tmp/ubuntu/cb4045a9-a22f-409c-badd-da6f2341b370/hive_2016-09-24_21-19-53_325_394320563611715555-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable (7963 bytes)
2016-09-24 21:24:55	End of local task; Time Taken: 1.672 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 7 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0415, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0415/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0415
Hadoop job information for Stage-18: number of mappers: 2; number of reducers: 0
2016-09-24 21:25:01,234 Stage-18 map = 0%,  reduce = 0%
2016-09-24 21:25:15,661 Stage-18 map = 100%,  reduce = 0%, Cumulative CPU 22.37 sec
MapReduce Total cumulative CPU time: 22 seconds 370 msec
Ended Job = job_1474660851143_0415
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924211953_75fabfff-bc0b-4098-b5a5-3807dcbfc42a.log
2016-09-24 21:25:19	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:25:21	Dump the side-table for tag: 1 with group count: 39 into file: file:/tmp/ubuntu/cb4045a9-a22f-409c-badd-da6f2341b370/hive_2016-09-24_21-19-53_325_394320563611715555-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable
2016-09-24 21:25:21	Uploaded 1 File to: file:/tmp/ubuntu/cb4045a9-a22f-409c-badd-da6f2341b370/hive_2016-09-24_21-19-53_325_394320563611715555-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (1662 bytes)
2016-09-24 21:25:21	End of local task; Time Taken: 1.351 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 8 out of 16
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0416, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0416/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0416
Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1
2016-09-24 21:25:26,654 Stage-8 map = 0%,  reduce = 0%
2016-09-24 21:25:36,881 Stage-8 map = 33%,  reduce = 0%, Cumulative CPU 7.26 sec
2016-09-24 21:25:38,932 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 8.81 sec
2016-09-24 21:25:45,319 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 10.59 sec
MapReduce Total cumulative CPU time: 10 seconds 590 msec
Ended Job = job_1474660851143_0416
Launching Job 9 out of 16
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0417, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0417/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0417
Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 1
2016-09-24 21:25:51,605 Stage-9 map = 0%,  reduce = 0%
2016-09-24 21:25:56,778 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 1.22 sec
2016-09-24 21:26:02,956 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 2.48 sec
MapReduce Total cumulative CPU time: 2 seconds 480 msec
Ended Job = job_1474660851143_0417
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 30  Reduce: 32   Cumulative CPU: 541.76 sec   HDFS Read: 8124263511 HDFS Write: 226967742 SUCCESS
Stage-Stage-30: Map: 4   Cumulative CPU: 35.48 sec   HDFS Read: 227005626 HDFS Write: 235481551 SUCCESS
Stage-Stage-3: Map: 5  Reduce: 2   Cumulative CPU: 83.14 sec   HDFS Read: 316193658 HDFS Write: 293830002 SUCCESS
Stage-Stage-4: Map: 6  Reduce: 2   Cumulative CPU: 92.99 sec   HDFS Read: 374559002 HDFS Write: 348836292 SUCCESS
Stage-Stage-5: Map: 3  Reduce: 2   Cumulative CPU: 85.87 sec   HDFS Read: 391384296 HDFS Write: 419920173 SUCCESS
Stage-Stage-18: Map: 2   Cumulative CPU: 22.37 sec   HDFS Read: 419944881 HDFS Write: 85556507 SUCCESS
Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 10.59 sec   HDFS Read: 85590103 HDFS Write: 1858 SUCCESS
Stage-Stage-9: Map: 1  Reduce: 1   Cumulative CPU: 2.48 sec   HDFS Read: 7065 HDFS Write: 1783 SUCCESS
Total MapReduce CPU Time Spent: 14 minutes 34 seconds 680 msec
OK
Did not fit	36.4	922.3180053710937	44.14999961853027
Did not like the col	7.0	65.66000366210938	52.52000045776367
Did not like the mak	12.0	359.4599914550781	34.9900016784668
Did not like the mod	4.5	96.23500061035156	18.535000205039978
Found a better exten	5.0	65.47000122070312	41.73500061035156
Found a better price	21.5	365.5500011444092	44.73249959945679
Gift exchange	15.5	502.5549907684326	48.635000228881836
No service location 	18.0	670.0650100708008	32.06499934196472
Not working any more	22.0	90.98999977111816	20.105000019073486
Package was damaged	19.0	941.0019750595093	31.7440003156662
Parts missing	14.333333333333334	213.90000025431314	57.020002365112305
Stopped working	27.0	452.43249130249023	70.0649995803833
Wrong size	23.5	431.12999725341797	65.73999786376953
duplicate purchase	18.0	0.0	5.519999980926514
it is a girl	10.5	474.72498321533203	29.644999027252197
its is a boy	27.5	196.35500717163086	26.50499999523163
reason 24	9.75	172.76999378204346	65.16749954223633
reason 25	9.0	259.3500061035156	52.0099983215332
reason 26	5.0	248.11000061035156	74.68000030517578
reason 27	25.666666666666668	467.3833363850911	38.336666107177734
reason 28	42.0	497.6000061035156	64.03499984741211
reason 29	22.0	374.82666810353595	44.30666542053223
reason 31	36.25	760.8725032806396	54.20750141143799
reason 32	44.0	92.88000297546387	75.44499969482422
reason 33	9.0	180.9300038019816	45.070000330607094
reason 34	31.0	263.83998918533325	33.27000069618225
reason 35	6.0	558.7899780273438	70.2300033569336
reason 36	14.0	407.8599853515625	67.08999633789062
reason 37	24.0	526.3600006103516	57.30000114440918
reason 38	9.0	146.94749927520752	21.157500505447388
reason 39	52.5	675.9999961853027	43.98499870300293
unauthoized purchase	37.0	761.5599975585938	43.720001220703125
Time taken: 370.74 seconds, Fetched: 32 row(s)
Query 85: Total Execution Time = 379 seconds

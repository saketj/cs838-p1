
Logging initialized using configuration in jar:file:/home/ubuntu/software/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties
Hive history file=/tmp/ubuntu/hive_job_log_d993ddc6-36a0-4c5b-a068-fce39e0703b9_1733974245.txt
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 0.972 seconds
Query ID = ubuntu_20160924210311_b7e0603a-29d1-41a3-a9f1-fa36b695c256
Total jobs = 16
Stage-1 is selected by condition resolver.
Launching Job 1 out of 16
Number of reduce tasks not specified. Estimated from input data size: 32
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0401, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0401/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0401
Hadoop job information for Stage-1: number of mappers: 30; number of reducers: 32
2016-09-24 21:03:23,774 Stage-1 map = 0%,  reduce = 0%
2016-09-24 21:03:36,343 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 17.01 sec
2016-09-24 21:03:37,389 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 67.09 sec
2016-09-24 21:03:41,575 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 80.86 sec
2016-09-24 21:03:42,621 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 85.92 sec
2016-09-24 21:03:43,662 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 92.77 sec
2016-09-24 21:03:45,735 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 99.54 sec
2016-09-24 21:03:46,788 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 107.53 sec
2016-09-24 21:03:50,941 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 127.09 sec
2016-09-24 21:03:52,031 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 131.38 sec
2016-09-24 21:03:53,097 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 142.46 sec
2016-09-24 21:03:54,157 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 145.54 sec
2016-09-24 21:03:55,243 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 157.96 sec
2016-09-24 21:03:56,290 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 175.7 sec
2016-09-24 21:03:57,338 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 181.49 sec
2016-09-24 21:03:58,385 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 190.79 sec
2016-09-24 21:04:01,532 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 197.88 sec
2016-09-24 21:04:04,648 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 207.77 sec
2016-09-24 21:04:06,721 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 231.5 sec
2016-09-24 21:04:07,773 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 241.77 sec
2016-09-24 21:04:08,816 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 261.87 sec
2016-09-24 21:04:09,863 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 267.21 sec
2016-09-24 21:04:10,911 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 274.08 sec
2016-09-24 21:04:11,949 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 278.91 sec
2016-09-24 21:04:12,995 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 283.9 sec
2016-09-24 21:04:14,045 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 290.57 sec
2016-09-24 21:04:15,112 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 293.62 sec
2016-09-24 21:04:17,176 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 302.25 sec
2016-09-24 21:04:18,218 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 305.56 sec
2016-09-24 21:04:19,257 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 310.42 sec
2016-09-24 21:04:20,293 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 314.66 sec
2016-09-24 21:04:21,330 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 317.07 sec
2016-09-24 21:04:23,403 Stage-1 map = 91%,  reduce = 0%, Cumulative CPU 325.01 sec
2016-09-24 21:04:24,440 Stage-1 map = 95%,  reduce = 0%, Cumulative CPU 329.74 sec
2016-09-24 21:04:25,477 Stage-1 map = 96%,  reduce = 0%, Cumulative CPU 332.41 sec
2016-09-24 21:04:26,510 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 339.54 sec
2016-09-24 21:04:36,931 Stage-1 map = 100%,  reduce = 3%, Cumulative CPU 345.71 sec
2016-09-24 21:04:38,024 Stage-1 map = 100%,  reduce = 13%, Cumulative CPU 366.01 sec
2016-09-24 21:04:39,089 Stage-1 map = 100%,  reduce = 24%, Cumulative CPU 388.68 sec
2016-09-24 21:04:40,150 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 392.11 sec
2016-09-24 21:04:41,203 Stage-1 map = 100%,  reduce = 38%, Cumulative CPU 417.32 sec
2016-09-24 21:04:42,260 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 442.11 sec
2016-09-24 21:04:48,569 Stage-1 map = 100%,  reduce = 56%, Cumulative CPU 454.38 sec
2016-09-24 21:04:49,602 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 466.32 sec
2016-09-24 21:04:50,636 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 492.86 sec
2016-09-24 21:04:51,670 Stage-1 map = 100%,  reduce = 81%, Cumulative CPU 506.58 sec
2016-09-24 21:04:52,703 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 531.15 sec
2016-09-24 21:04:53,735 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 543.7 sec
MapReduce Total cumulative CPU time: 9 minutes 3 seconds 700 msec
Ended Job = job_1474660851143_0401
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924210311_b7e0603a-29d1-41a3-a9f1-fa36b695c256.log
2016-09-24 21:04:57	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:04:58	Dump the side-table for tag: 1 with group count: 876 into file: file:/tmp/ubuntu/d993ddc6-36a0-4c5b-a068-fce39e0703b9/hive_2016-09-24_21-03-11_570_3110576588730675706-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable
2016-09-24 21:04:58	Uploaded 1 File to: file:/tmp/ubuntu/d993ddc6-36a0-4c5b-a068-fce39e0703b9/hive_2016-09-24_21-03-11_570_3110576588730675706-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable (17481 bytes)
2016-09-24 21:04:58	End of local task; Time Taken: 1.279 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 2 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0402, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0402/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0402
Hadoop job information for Stage-30: number of mappers: 4; number of reducers: 0
2016-09-24 21:05:04,397 Stage-30 map = 0%,  reduce = 0%
2016-09-24 21:05:16,733 Stage-30 map = 19%,  reduce = 0%, Cumulative CPU 11.71 sec
2016-09-24 21:05:17,767 Stage-30 map = 38%,  reduce = 0%, Cumulative CPU 23.22 sec
2016-09-24 21:05:19,831 Stage-30 map = 66%,  reduce = 0%, Cumulative CPU 29.24 sec
2016-09-24 21:05:20,865 Stage-30 map = 100%,  reduce = 0%, Cumulative CPU 36.5 sec
MapReduce Total cumulative CPU time: 36 seconds 500 msec
Ended Job = job_1474660851143_0402
Stage-41 is filtered out by condition resolver.
Stage-42 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Launching Job 3 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0403, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0403/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0403
Hadoop job information for Stage-3: number of mappers: 5; number of reducers: 2
2016-09-24 21:05:27,797 Stage-3 map = 0%,  reduce = 0%
2016-09-24 21:05:38,042 Stage-3 map = 3%,  reduce = 0%, Cumulative CPU 7.1 sec
2016-09-24 21:05:40,099 Stage-3 map = 68%,  reduce = 0%, Cumulative CPU 22.58 sec
2016-09-24 21:05:41,128 Stage-3 map = 78%,  reduce = 0%, Cumulative CPU 26.91 sec
2016-09-24 21:05:42,158 Stage-3 map = 87%,  reduce = 0%, Cumulative CPU 28.3 sec
2016-09-24 21:05:44,218 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 31.37 sec
2016-09-24 21:05:47,300 Stage-3 map = 93%,  reduce = 0%, Cumulative CPU 34.58 sec
2016-09-24 21:05:54,474 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 41.91 sec
2016-09-24 21:06:04,757 Stage-3 map = 100%,  reduce = 36%, Cumulative CPU 49.36 sec
2016-09-24 21:06:05,801 Stage-3 map = 100%,  reduce = 72%, Cumulative CPU 57.02 sec
2016-09-24 21:06:07,855 Stage-3 map = 100%,  reduce = 76%, Cumulative CPU 60.2 sec
2016-09-24 21:06:08,888 Stage-3 map = 100%,  reduce = 79%, Cumulative CPU 63.41 sec
2016-09-24 21:06:10,947 Stage-3 map = 100%,  reduce = 87%, Cumulative CPU 66.6 sec
2016-09-24 21:06:14,037 Stage-3 map = 100%,  reduce = 94%, Cumulative CPU 75.81 sec
2016-09-24 21:06:15,067 Stage-3 map = 100%,  reduce = 96%, Cumulative CPU 77.44 sec
2016-09-24 21:06:17,123 Stage-3 map = 100%,  reduce = 99%, Cumulative CPU 80.26 sec
2016-09-24 21:06:19,175 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 80.96 sec
MapReduce Total cumulative CPU time: 1 minutes 20 seconds 960 msec
Ended Job = job_1474660851143_0403
Stage-39 is filtered out by condition resolver.
Stage-40 is filtered out by condition resolver.
Stage-4 is selected by condition resolver.
Launching Job 4 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0404, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0404/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0404
Hadoop job information for Stage-4: number of mappers: 6; number of reducers: 2
2016-09-24 21:06:25,142 Stage-4 map = 0%,  reduce = 0%
2016-09-24 21:06:36,550 Stage-4 map = 33%,  reduce = 0%, Cumulative CPU 9.07 sec
2016-09-24 21:06:37,596 Stage-4 map = 67%,  reduce = 0%, Cumulative CPU 30.49 sec
2016-09-24 21:06:43,797 Stage-4 map = 89%,  reduce = 0%, Cumulative CPU 43.35 sec
2016-09-24 21:06:45,860 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 47.57 sec
2016-09-24 21:06:57,188 Stage-4 map = 100%,  reduce = 50%, Cumulative CPU 53.2 sec
2016-09-24 21:07:00,279 Stage-4 map = 100%,  reduce = 70%, Cumulative CPU 61.37 sec
2016-09-24 21:07:03,382 Stage-4 map = 100%,  reduce = 77%, Cumulative CPU 67.84 sec
2016-09-24 21:07:06,470 Stage-4 map = 100%,  reduce = 83%, Cumulative CPU 74.25 sec
2016-09-24 21:07:08,537 Stage-4 map = 100%,  reduce = 86%, Cumulative CPU 77.47 sec
2016-09-24 21:07:09,570 Stage-4 map = 100%,  reduce = 89%, Cumulative CPU 80.67 sec
2016-09-24 21:07:11,633 Stage-4 map = 100%,  reduce = 93%, Cumulative CPU 83.92 sec
2016-09-24 21:07:12,679 Stage-4 map = 100%,  reduce = 96%, Cumulative CPU 87.2 sec
2016-09-24 21:07:13,714 Stage-4 map = 100%,  reduce = 97%, Cumulative CPU 88.49 sec
2016-09-24 21:07:14,753 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 90.96 sec
MapReduce Total cumulative CPU time: 1 minutes 30 seconds 960 msec
Ended Job = job_1474660851143_0404
Stage-37 is filtered out by condition resolver.
Stage-38 is filtered out by condition resolver.
Stage-5 is selected by condition resolver.
Launching Job 5 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0405, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0405/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0405
Hadoop job information for Stage-5: number of mappers: 3; number of reducers: 2
2016-09-24 21:07:20,645 Stage-5 map = 0%,  reduce = 0%
2016-09-24 21:07:32,952 Stage-5 map = 33%,  reduce = 0%, Cumulative CPU 4.38 sec
2016-09-24 21:07:41,148 Stage-5 map = 68%,  reduce = 0%, Cumulative CPU 30.15 sec
2016-09-24 21:07:44,230 Stage-5 map = 78%,  reduce = 0%, Cumulative CPU 36.66 sec
2016-09-24 21:07:45,267 Stage-5 map = 89%,  reduce = 0%, Cumulative CPU 38.67 sec
2016-09-24 21:07:46,297 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 40.75 sec
2016-09-24 21:07:56,550 Stage-5 map = 100%,  reduce = 72%, Cumulative CPU 55.34 sec
2016-09-24 21:07:59,623 Stage-5 map = 100%,  reduce = 78%, Cumulative CPU 61.84 sec
2016-09-24 21:08:02,705 Stage-5 map = 100%,  reduce = 84%, Cumulative CPU 68.28 sec
2016-09-24 21:08:05,781 Stage-5 map = 100%,  reduce = 91%, Cumulative CPU 74.88 sec
2016-09-24 21:08:08,857 Stage-5 map = 100%,  reduce = 97%, Cumulative CPU 81.35 sec
2016-09-24 21:08:09,885 Stage-5 map = 100%,  reduce = 98%, Cumulative CPU 82.41 sec
2016-09-24 21:08:10,922 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 84.77 sec
MapReduce Total cumulative CPU time: 1 minutes 24 seconds 770 msec
Ended Job = job_1474660851143_0405
Stage-35 is selected by condition resolver.
Stage-36 is filtered out by condition resolver.
Stage-6 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924210311_b7e0603a-29d1-41a3-a9f1-fa36b695c256.log
2016-09-24 21:08:15	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:08:17	Dump the side-table for tag: 1 with group count: 365 into file: file:/tmp/ubuntu/d993ddc6-36a0-4c5b-a068-fce39e0703b9/hive_2016-09-24_21-03-11_570_3110576588730675706-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable
2016-09-24 21:08:17	Uploaded 1 File to: file:/tmp/ubuntu/d993ddc6-36a0-4c5b-a068-fce39e0703b9/hive_2016-09-24_21-03-11_570_3110576588730675706-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable (7963 bytes)
2016-09-24 21:08:17	End of local task; Time Taken: 1.666 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 7 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0406, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0406/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0406
Hadoop job information for Stage-18: number of mappers: 2; number of reducers: 0
2016-09-24 21:08:22,890 Stage-18 map = 0%,  reduce = 0%
2016-09-24 21:08:36,296 Stage-18 map = 64%,  reduce = 0%, Cumulative CPU 21.1 sec
2016-09-24 21:08:37,328 Stage-18 map = 100%,  reduce = 0%, Cumulative CPU 21.83 sec
MapReduce Total cumulative CPU time: 21 seconds 830 msec
Ended Job = job_1474660851143_0406
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924210311_b7e0603a-29d1-41a3-a9f1-fa36b695c256.log
2016-09-24 21:08:41	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:08:42	Dump the side-table for tag: 1 with group count: 39 into file: file:/tmp/ubuntu/d993ddc6-36a0-4c5b-a068-fce39e0703b9/hive_2016-09-24_21-03-11_570_3110576588730675706-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable
2016-09-24 21:08:42	Uploaded 1 File to: file:/tmp/ubuntu/d993ddc6-36a0-4c5b-a068-fce39e0703b9/hive_2016-09-24_21-03-11_570_3110576588730675706-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (1662 bytes)
2016-09-24 21:08:42	End of local task; Time Taken: 1.222 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 8 out of 16
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0407, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0407/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0407
Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1
2016-09-24 21:08:47,773 Stage-8 map = 0%,  reduce = 0%
2016-09-24 21:08:58,010 Stage-8 map = 33%,  reduce = 0%, Cumulative CPU 7.24 sec
2016-09-24 21:08:59,041 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 8.67 sec
2016-09-24 21:09:06,211 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 10.47 sec
MapReduce Total cumulative CPU time: 10 seconds 470 msec
Ended Job = job_1474660851143_0407
Launching Job 9 out of 16
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0408, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0408/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0408
Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 1
2016-09-24 21:09:12,061 Stage-9 map = 0%,  reduce = 0%
2016-09-24 21:09:17,214 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 1.04 sec
2016-09-24 21:09:23,389 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 2.44 sec
MapReduce Total cumulative CPU time: 2 seconds 440 msec
Ended Job = job_1474660851143_0408
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 30  Reduce: 32   Cumulative CPU: 543.7 sec   HDFS Read: 8124263543 HDFS Write: 226967742 SUCCESS
Stage-Stage-30: Map: 4   Cumulative CPU: 36.5 sec   HDFS Read: 227005674 HDFS Write: 235481531 SUCCESS
Stage-Stage-3: Map: 5  Reduce: 2   Cumulative CPU: 80.96 sec   HDFS Read: 316193649 HDFS Write: 293830062 SUCCESS
Stage-Stage-4: Map: 6  Reduce: 2   Cumulative CPU: 90.96 sec   HDFS Read: 374559331 HDFS Write: 348836332 SUCCESS
Stage-Stage-5: Map: 3  Reduce: 2   Cumulative CPU: 84.77 sec   HDFS Read: 391387293 HDFS Write: 419920233 SUCCESS
Stage-Stage-18: Map: 2   Cumulative CPU: 21.83 sec   HDFS Read: 419949024 HDFS Write: 85556567 SUCCESS
Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 10.47 sec   HDFS Read: 85590169 HDFS Write: 1858 SUCCESS
Stage-Stage-9: Map: 1  Reduce: 1   Cumulative CPU: 2.44 sec   HDFS Read: 7071 HDFS Write: 1783 SUCCESS
Total MapReduce CPU Time Spent: 14 minutes 31 seconds 630 msec
OK
Did not fit	36.4	922.3180053710937	44.14999961853027
Did not like the col	7.0	65.66000366210938	52.52000045776367
Did not like the mak	12.0	359.4599914550781	34.9900016784668
Did not like the mod	4.5	96.23500061035156	18.535000205039978
Found a better exten	5.0	65.47000122070312	41.73500061035156
Found a better price	21.5	365.5500011444092	44.73249959945679
Gift exchange	15.5	502.5549907684326	48.635000228881836
No service location 	18.0	670.0650100708008	32.06499934196472
Not working any more	22.0	90.98999977111816	20.105000019073486
Package was damaged	19.0	941.0019750595093	31.7440003156662
Parts missing	14.333333333333334	213.90000025431314	57.020002365112305
Stopped working	27.0	452.43249130249023	70.0649995803833
Wrong size	23.5	431.12999725341797	65.73999786376953
duplicate purchase	18.0	0.0	5.519999980926514
it is a girl	10.5	474.72498321533203	29.644999027252197
its is a boy	27.5	196.35500717163086	26.50499999523163
reason 24	9.75	172.76999378204346	65.16749954223633
reason 25	9.0	259.3500061035156	52.0099983215332
reason 26	5.0	248.11000061035156	74.68000030517578
reason 27	25.666666666666668	467.3833363850911	38.336666107177734
reason 28	42.0	497.6000061035156	64.03499984741211
reason 29	22.0	374.82666810353595	44.30666542053223
reason 31	36.25	760.8725032806396	54.20750141143799
reason 32	44.0	92.88000297546387	75.44499969482422
reason 33	9.0	180.9300038019816	45.070000330607094
reason 34	31.0	263.83998918533325	33.27000069618225
reason 35	6.0	558.7899780273438	70.2300033569336
reason 36	14.0	407.8599853515625	67.08999633789062
reason 37	24.0	526.3600006103516	57.30000114440918
reason 38	9.0	146.94749927520752	21.157500505447388
reason 39	52.5	675.9999961853027	43.98499870300293
unauthoized purchase	37.0	761.5599975585938	43.720001220703125
Time taken: 373.968 seconds, Fetched: 32 row(s)
Query 85: Total Execution Time = 381 seconds


Logging initialized using configuration in jar:file:/home/ubuntu/software/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties
Hive history file=/tmp/ubuntu/hive_job_log_a305d66a-3f98-4995-b52c-4462e9d113c4_1939818487.txt
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 0.956 seconds
Query ID = ubuntu_20160924213639_d4d63897-1350-4ebd-b64c-291979f11ffb
Total jobs = 16
Stage-1 is selected by condition resolver.
Launching Job 1 out of 16
Number of reduce tasks not specified. Estimated from input data size: 32
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0419, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0419/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0419
Hadoop job information for Stage-1: number of mappers: 30; number of reducers: 32
2016-09-24 21:36:53,960 Stage-1 map = 0%,  reduce = 0%
2016-09-24 21:37:06,553 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 33.29 sec
2016-09-24 21:37:07,600 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 49.12 sec
2016-09-24 21:37:11,760 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 84.92 sec
2016-09-24 21:37:12,814 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 93.59 sec
2016-09-24 21:37:13,852 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 94.34 sec
2016-09-24 21:37:14,898 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 98.73 sec
2016-09-24 21:37:15,955 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 108.55 sec
2016-09-24 21:37:18,031 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 113.99 sec
2016-09-24 21:37:19,077 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 122.62 sec
2016-09-24 21:37:21,179 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 131.92 sec
2016-09-24 21:37:22,259 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 143.84 sec
2016-09-24 21:37:23,335 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 156.35 sec
2016-09-24 21:37:24,396 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 168.58 sec
2016-09-24 21:37:25,443 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 183.11 sec
2016-09-24 21:37:26,519 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 190.57 sec
2016-09-24 21:37:28,622 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 192.54 sec
2016-09-24 21:37:32,774 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 201.62 sec
2016-09-24 21:37:35,884 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 233.78 sec
2016-09-24 21:37:36,926 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 248.92 sec
2016-09-24 21:37:37,966 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 259.43 sec
2016-09-24 21:37:39,006 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 266.84 sec
2016-09-24 21:37:40,051 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 271.47 sec
2016-09-24 21:37:41,090 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 276.4 sec
2016-09-24 21:37:42,137 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 282.39 sec
2016-09-24 21:37:43,180 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 287.34 sec
2016-09-24 21:37:44,246 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 292.0 sec
2016-09-24 21:37:45,281 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 300.72 sec
2016-09-24 21:37:46,318 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 304.0 sec
2016-09-24 21:37:47,359 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 306.53 sec
2016-09-24 21:37:48,407 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 310.2 sec
2016-09-24 21:37:49,444 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 316.73 sec
2016-09-24 21:37:50,479 Stage-1 map = 89%,  reduce = 0%, Cumulative CPU 321.88 sec
2016-09-24 21:37:51,513 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 328.2 sec
2016-09-24 21:37:52,546 Stage-1 map = 99%,  reduce = 0%, Cumulative CPU 335.16 sec
2016-09-24 21:37:55,637 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 338.03 sec
2016-09-24 21:38:06,031 Stage-1 map = 100%,  reduce = 9%, Cumulative CPU 356.52 sec
2016-09-24 21:38:07,080 Stage-1 map = 100%,  reduce = 12%, Cumulative CPU 363.83 sec
2016-09-24 21:38:08,135 Stage-1 map = 100%,  reduce = 24%, Cumulative CPU 388.15 sec
2016-09-24 21:38:09,176 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 391.07 sec
2016-09-24 21:38:10,234 Stage-1 map = 100%,  reduce = 44%, Cumulative CPU 427.97 sec
2016-09-24 21:38:11,280 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 440.58 sec
2016-09-24 21:38:17,549 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 465.59 sec
2016-09-24 21:38:18,596 Stage-1 map = 100%,  reduce = 65%, Cumulative CPU 473.36 sec
2016-09-24 21:38:19,668 Stage-1 map = 100%,  reduce = 75%, Cumulative CPU 493.07 sec
2016-09-24 21:38:20,712 Stage-1 map = 100%,  reduce = 81%, Cumulative CPU 505.86 sec
2016-09-24 21:38:21,747 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 530.41 sec
2016-09-24 21:38:22,779 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 542.82 sec
MapReduce Total cumulative CPU time: 9 minutes 2 seconds 820 msec
Ended Job = job_1474660851143_0419
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924213639_d4d63897-1350-4ebd-b64c-291979f11ffb.log
2016-09-24 21:38:26	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:38:27	Dump the side-table for tag: 1 with group count: 876 into file: file:/tmp/ubuntu/a305d66a-3f98-4995-b52c-4462e9d113c4/hive_2016-09-24_21-36-39_924_8048871408104837149-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable
2016-09-24 21:38:27	Uploaded 1 File to: file:/tmp/ubuntu/a305d66a-3f98-4995-b52c-4462e9d113c4/hive_2016-09-24_21-36-39_924_8048871408104837149-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable (17481 bytes)
2016-09-24 21:38:27	End of local task; Time Taken: 1.215 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 2 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0420, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0420/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0420
Hadoop job information for Stage-30: number of mappers: 4; number of reducers: 0
2016-09-24 21:38:33,818 Stage-30 map = 0%,  reduce = 0%
2016-09-24 21:38:46,276 Stage-30 map = 41%,  reduce = 0%, Cumulative CPU 23.05 sec
2016-09-24 21:38:49,407 Stage-30 map = 100%,  reduce = 0%, Cumulative CPU 34.76 sec
MapReduce Total cumulative CPU time: 34 seconds 760 msec
Ended Job = job_1474660851143_0420
Stage-41 is filtered out by condition resolver.
Stage-42 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Launching Job 3 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0421, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0421/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0421
Hadoop job information for Stage-3: number of mappers: 5; number of reducers: 2
2016-09-24 21:38:56,452 Stage-3 map = 0%,  reduce = 0%
2016-09-24 21:39:05,821 Stage-3 map = 20%,  reduce = 0%, Cumulative CPU 4.33 sec
2016-09-24 21:39:08,928 Stage-3 map = 53%,  reduce = 0%, Cumulative CPU 12.75 sec
2016-09-24 21:39:09,968 Stage-3 map = 77%,  reduce = 0%, Cumulative CPU 23.16 sec
2016-09-24 21:39:11,002 Stage-3 map = 83%,  reduce = 0%, Cumulative CPU 24.35 sec
2016-09-24 21:39:15,140 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 30.66 sec
2016-09-24 21:39:18,242 Stage-3 map = 93%,  reduce = 0%, Cumulative CPU 33.72 sec
2016-09-24 21:39:25,466 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 40.75 sec
2016-09-24 21:39:35,816 Stage-3 map = 100%,  reduce = 72%, Cumulative CPU 55.68 sec
2016-09-24 21:39:38,916 Stage-3 map = 100%,  reduce = 79%, Cumulative CPU 62.14 sec
2016-09-24 21:39:42,013 Stage-3 map = 100%,  reduce = 87%, Cumulative CPU 68.53 sec
2016-09-24 21:39:45,108 Stage-3 map = 100%,  reduce = 94%, Cumulative CPU 74.99 sec
2016-09-24 21:39:46,153 Stage-3 map = 100%,  reduce = 96%, Cumulative CPU 76.43 sec
2016-09-24 21:39:48,220 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 79.98 sec
MapReduce Total cumulative CPU time: 1 minutes 19 seconds 980 msec
Ended Job = job_1474660851143_0421
Stage-39 is filtered out by condition resolver.
Stage-40 is filtered out by condition resolver.
Stage-4 is selected by condition resolver.
Launching Job 4 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0422, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0422/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0422
Hadoop job information for Stage-4: number of mappers: 6; number of reducers: 2
2016-09-24 21:39:55,166 Stage-4 map = 0%,  reduce = 0%
2016-09-24 21:40:03,407 Stage-4 map = 33%,  reduce = 0%, Cumulative CPU 9.06 sec
2016-09-24 21:40:07,544 Stage-4 map = 67%,  reduce = 0%, Cumulative CPU 24.7 sec
2016-09-24 21:40:13,726 Stage-4 map = 77%,  reduce = 0%, Cumulative CPU 40.12 sec
2016-09-24 21:40:14,758 Stage-4 map = 87%,  reduce = 0%, Cumulative CPU 43.41 sec
2016-09-24 21:40:16,816 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 49.58 sec
2016-09-24 21:40:28,137 Stage-4 map = 100%,  reduce = 69%, Cumulative CPU 62.39 sec
2016-09-24 21:40:30,202 Stage-4 map = 100%,  reduce = 72%, Cumulative CPU 65.63 sec
2016-09-24 21:40:31,236 Stage-4 map = 100%,  reduce = 76%, Cumulative CPU 68.89 sec
2016-09-24 21:40:33,294 Stage-4 map = 100%,  reduce = 79%, Cumulative CPU 72.04 sec
2016-09-24 21:40:34,330 Stage-4 map = 100%,  reduce = 82%, Cumulative CPU 75.3 sec
2016-09-24 21:40:36,389 Stage-4 map = 100%,  reduce = 86%, Cumulative CPU 78.44 sec
2016-09-24 21:40:37,426 Stage-4 map = 100%,  reduce = 89%, Cumulative CPU 81.65 sec
2016-09-24 21:40:39,487 Stage-4 map = 100%,  reduce = 92%, Cumulative CPU 84.91 sec
2016-09-24 21:40:40,522 Stage-4 map = 100%,  reduce = 96%, Cumulative CPU 88.22 sec
2016-09-24 21:40:42,585 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 92.63 sec
MapReduce Total cumulative CPU time: 1 minutes 32 seconds 630 msec
Ended Job = job_1474660851143_0422
Stage-37 is filtered out by condition resolver.
Stage-38 is filtered out by condition resolver.
Stage-5 is selected by condition resolver.
Launching Job 5 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0423, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0423/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0423
Hadoop job information for Stage-5: number of mappers: 3; number of reducers: 2
2016-09-24 21:40:49,935 Stage-5 map = 0%,  reduce = 0%
2016-09-24 21:41:01,200 Stage-5 map = 33%,  reduce = 0%, Cumulative CPU 11.24 sec
2016-09-24 21:41:07,349 Stage-5 map = 50%,  reduce = 0%, Cumulative CPU 27.23 sec
2016-09-24 21:41:08,379 Stage-5 map = 68%,  reduce = 0%, Cumulative CPU 30.52 sec
2016-09-24 21:41:10,433 Stage-5 map = 73%,  reduce = 0%, Cumulative CPU 33.68 sec
2016-09-24 21:41:11,462 Stage-5 map = 78%,  reduce = 0%, Cumulative CPU 37.0 sec
2016-09-24 21:41:13,528 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 42.08 sec
2016-09-24 21:41:23,775 Stage-5 map = 100%,  reduce = 72%, Cumulative CPU 56.85 sec
2016-09-24 21:41:26,856 Stage-5 map = 100%,  reduce = 78%, Cumulative CPU 63.45 sec
2016-09-24 21:41:29,933 Stage-5 map = 100%,  reduce = 85%, Cumulative CPU 69.94 sec
2016-09-24 21:41:33,018 Stage-5 map = 100%,  reduce = 91%, Cumulative CPU 76.63 sec
2016-09-24 21:41:36,095 Stage-5 map = 100%,  reduce = 98%, Cumulative CPU 83.05 sec
2016-09-24 21:41:39,171 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 85.57 sec
MapReduce Total cumulative CPU time: 1 minutes 25 seconds 570 msec
Ended Job = job_1474660851143_0423
Stage-35 is selected by condition resolver.
Stage-36 is filtered out by condition resolver.
Stage-6 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924213639_d4d63897-1350-4ebd-b64c-291979f11ffb.log
2016-09-24 21:41:43	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:41:47	Dump the side-table for tag: 1 with group count: 365 into file: file:/tmp/ubuntu/a305d66a-3f98-4995-b52c-4462e9d113c4/hive_2016-09-24_21-36-39_924_8048871408104837149-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable
2016-09-24 21:41:47	Uploaded 1 File to: file:/tmp/ubuntu/a305d66a-3f98-4995-b52c-4462e9d113c4/hive_2016-09-24_21-36-39_924_8048871408104837149-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable (7963 bytes)
2016-09-24 21:41:47	End of local task; Time Taken: 4.501 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 7 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0424, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0424/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0424
Hadoop job information for Stage-18: number of mappers: 2; number of reducers: 0
2016-09-24 21:41:53,332 Stage-18 map = 0%,  reduce = 0%
2016-09-24 21:42:07,839 Stage-18 map = 100%,  reduce = 0%, Cumulative CPU 21.14 sec
MapReduce Total cumulative CPU time: 21 seconds 140 msec
Ended Job = job_1474660851143_0424
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924213639_d4d63897-1350-4ebd-b64c-291979f11ffb.log
2016-09-24 21:42:12	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:42:13	Dump the side-table for tag: 1 with group count: 39 into file: file:/tmp/ubuntu/a305d66a-3f98-4995-b52c-4462e9d113c4/hive_2016-09-24_21-36-39_924_8048871408104837149-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable
2016-09-24 21:42:13	Uploaded 1 File to: file:/tmp/ubuntu/a305d66a-3f98-4995-b52c-4462e9d113c4/hive_2016-09-24_21-36-39_924_8048871408104837149-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (1662 bytes)
2016-09-24 21:42:13	End of local task; Time Taken: 1.184 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 8 out of 16
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0425, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0425/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0425
Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1
2016-09-24 21:42:20,821 Stage-8 map = 0%,  reduce = 0%
2016-09-24 21:42:31,095 Stage-8 map = 33%,  reduce = 0%, Cumulative CPU 7.25 sec
2016-09-24 21:42:32,129 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 8.97 sec
2016-09-24 21:42:38,296 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 10.76 sec
MapReduce Total cumulative CPU time: 10 seconds 760 msec
Ended Job = job_1474660851143_0425
Launching Job 9 out of 16
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0426, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0426/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0426
Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 1
2016-09-24 21:42:44,168 Stage-9 map = 0%,  reduce = 0%
2016-09-24 21:42:49,336 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 1.17 sec
2016-09-24 21:42:55,515 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 2.52 sec
MapReduce Total cumulative CPU time: 2 seconds 520 msec
Ended Job = job_1474660851143_0426
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 30  Reduce: 32   Cumulative CPU: 542.82 sec   HDFS Read: 8124263543 HDFS Write: 226967742 SUCCESS
Stage-Stage-30: Map: 4   Cumulative CPU: 34.76 sec   HDFS Read: 227005674 HDFS Write: 235481531 SUCCESS
Stage-Stage-3: Map: 5  Reduce: 2   Cumulative CPU: 79.98 sec   HDFS Read: 316193649 HDFS Write: 293830122 SUCCESS
Stage-Stage-4: Map: 6  Reduce: 2   Cumulative CPU: 92.63 sec   HDFS Read: 374559743 HDFS Write: 348836332 SUCCESS
Stage-Stage-5: Map: 3  Reduce: 2   Cumulative CPU: 85.57 sec   HDFS Read: 391387587 HDFS Write: 419920433 SUCCESS
Stage-Stage-18: Map: 2   Cumulative CPU: 21.14 sec   HDFS Read: 419946597 HDFS Write: 85556547 SUCCESS
Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 10.76 sec   HDFS Read: 85590149 HDFS Write: 1858 SUCCESS
Stage-Stage-9: Map: 1  Reduce: 1   Cumulative CPU: 2.52 sec   HDFS Read: 7071 HDFS Write: 1783 SUCCESS
Total MapReduce CPU Time Spent: 14 minutes 30 seconds 180 msec
OK
Did not fit	36.4	922.3180053710937	44.14999961853027
Did not like the col	7.0	65.66000366210938	52.52000045776367
Did not like the mak	12.0	359.4599914550781	34.9900016784668
Did not like the mod	4.5	96.23500061035156	18.535000205039978
Found a better exten	5.0	65.47000122070312	41.73500061035156
Found a better price	21.5	365.5500011444092	44.73249959945679
Gift exchange	15.5	502.5549907684326	48.635000228881836
No service location 	18.0	670.0650100708008	32.06499934196472
Not working any more	22.0	90.98999977111816	20.105000019073486
Package was damaged	19.0	941.0019750595093	31.7440003156662
Parts missing	14.333333333333334	213.90000025431314	57.020002365112305
Stopped working	27.0	452.43249130249023	70.0649995803833
Wrong size	23.5	431.12999725341797	65.73999786376953
duplicate purchase	18.0	0.0	5.519999980926514
it is a girl	10.5	474.72498321533203	29.644999027252197
its is a boy	27.5	196.35500717163086	26.50499999523163
reason 24	9.75	172.76999378204346	65.16749954223633
reason 25	9.0	259.3500061035156	52.0099983215332
reason 26	5.0	248.11000061035156	74.68000030517578
reason 27	25.666666666666668	467.3833363850911	38.336666107177734
reason 28	42.0	497.6000061035156	64.03499984741211
reason 29	22.0	374.82666810353595	44.30666542053223
reason 31	36.25	760.8725032806396	54.20750141143799
reason 32	44.0	92.88000297546387	75.44499969482422
reason 33	9.0	180.9300038019816	45.070000330607094
reason 34	31.0	263.83998918533325	33.27000069618225
reason 35	6.0	558.7899780273438	70.2300033569336
reason 36	14.0	407.8599853515625	67.08999633789062
reason 37	24.0	526.3600006103516	57.30000114440918
reason 38	9.0	146.94749927520752	21.157500505447388
reason 39	52.5	675.9999961853027	43.98499870300293
unauthoized purchase	37.0	761.5599975585938	43.720001220703125
Time taken: 376.721 seconds, Fetched: 32 row(s)
Query 85: Total Execution Time = 385 seconds

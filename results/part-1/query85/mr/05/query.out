
Logging initialized using configuration in jar:file:/home/ubuntu/software/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties
Hive history file=/tmp/ubuntu/hive_job_log_48fb8276-5285-4c43-992a-c9d4a1b1b697_1370316938.txt
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 0.959 seconds
Query ID = ubuntu_20160924215340_e48ea5f2-4ab3-44ea-bbbe-9345dde5a1df
Total jobs = 16
Stage-1 is selected by condition resolver.
Launching Job 1 out of 16
Number of reduce tasks not specified. Estimated from input data size: 32
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0428, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0428/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0428
Hadoop job information for Stage-1: number of mappers: 30; number of reducers: 32
2016-09-24 21:53:51,645 Stage-1 map = 0%,  reduce = 0%
2016-09-24 21:54:04,287 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 49.77 sec
2016-09-24 21:54:09,470 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 85.34 sec
2016-09-24 21:54:10,512 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 93.15 sec
2016-09-24 21:54:11,566 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 96.65 sec
2016-09-24 21:54:12,615 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 100.35 sec
2016-09-24 21:54:13,656 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 111.3 sec
2016-09-24 21:54:18,829 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 128.53 sec
2016-09-24 21:54:19,872 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 142.26 sec
2016-09-24 21:54:20,965 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 143.63 sec
2016-09-24 21:54:22,006 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 162.55 sec
2016-09-24 21:54:23,053 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 181.39 sec
2016-09-24 21:54:24,106 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 183.1 sec
2016-09-24 21:54:25,186 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 185.54 sec
2016-09-24 21:54:26,251 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 192.14 sec
2016-09-24 21:54:31,457 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 200.56 sec
2016-09-24 21:54:33,531 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 235.13 sec
2016-09-24 21:54:34,602 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 242.92 sec
2016-09-24 21:54:35,644 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 257.16 sec
2016-09-24 21:54:36,684 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 269.4 sec
2016-09-24 21:54:37,726 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 272.79 sec
2016-09-24 21:54:38,790 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 281.93 sec
2016-09-24 21:54:39,841 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 287.25 sec
2016-09-24 21:54:40,889 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 290.11 sec
2016-09-24 21:54:41,926 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 294.95 sec
2016-09-24 21:54:42,998 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 302.09 sec
2016-09-24 21:54:44,033 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 306.03 sec
2016-09-24 21:54:45,064 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 313.68 sec
2016-09-24 21:54:46,098 Stage-1 map = 91%,  reduce = 0%, Cumulative CPU 320.29 sec
2016-09-24 21:54:47,143 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 327.01 sec
2016-09-24 21:54:48,173 Stage-1 map = 97%,  reduce = 0%, Cumulative CPU 332.37 sec
2016-09-24 21:54:49,205 Stage-1 map = 98%,  reduce = 0%, Cumulative CPU 333.73 sec
2016-09-24 21:54:50,239 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 337.03 sec
2016-09-24 21:55:01,612 Stage-1 map = 100%,  reduce = 12%, Cumulative CPU 361.66 sec
2016-09-24 21:55:02,701 Stage-1 map = 100%,  reduce = 13%, Cumulative CPU 363.33 sec
2016-09-24 21:55:03,741 Stage-1 map = 100%,  reduce = 24%, Cumulative CPU 386.95 sec
2016-09-24 21:55:04,781 Stage-1 map = 100%,  reduce = 31%, Cumulative CPU 400.77 sec
2016-09-24 21:55:05,833 Stage-1 map = 100%,  reduce = 40%, Cumulative CPU 419.37 sec
2016-09-24 21:55:06,918 Stage-1 map = 100%,  reduce = 47%, Cumulative CPU 432.95 sec
2016-09-24 21:55:07,985 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 439.2 sec
2016-09-24 21:55:12,219 Stage-1 map = 100%,  reduce = 56%, Cumulative CPU 451.63 sec
2016-09-24 21:55:13,290 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 464.73 sec
2016-09-24 21:55:14,328 Stage-1 map = 100%,  reduce = 68%, Cumulative CPU 477.18 sec
2016-09-24 21:55:15,378 Stage-1 map = 100%,  reduce = 78%, Cumulative CPU 495.85 sec
2016-09-24 21:55:16,409 Stage-1 map = 100%,  reduce = 81%, Cumulative CPU 502.9 sec
2016-09-24 21:55:17,439 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 533.47 sec
2016-09-24 21:55:18,468 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 539.66 sec
MapReduce Total cumulative CPU time: 8 minutes 59 seconds 660 msec
Ended Job = job_1474660851143_0428
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924215340_e48ea5f2-4ab3-44ea-bbbe-9345dde5a1df.log
2016-09-24 21:55:22	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:55:23	Dump the side-table for tag: 1 with group count: 876 into file: file:/tmp/ubuntu/48fb8276-5285-4c43-992a-c9d4a1b1b697/hive_2016-09-24_21-53-40_195_1030987788315948952-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable
2016-09-24 21:55:23	Uploaded 1 File to: file:/tmp/ubuntu/48fb8276-5285-4c43-992a-c9d4a1b1b697/hive_2016-09-24_21-53-40_195_1030987788315948952-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable (17481 bytes)
2016-09-24 21:55:23	End of local task; Time Taken: 1.247 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 2 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0429, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0429/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0429
Hadoop job information for Stage-30: number of mappers: 4; number of reducers: 0
2016-09-24 21:55:29,306 Stage-30 map = 0%,  reduce = 0%
2016-09-24 21:55:41,605 Stage-30 map = 38%,  reduce = 0%, Cumulative CPU 23.2 sec
2016-09-24 21:55:44,686 Stage-30 map = 94%,  reduce = 0%, Cumulative CPU 34.57 sec
2016-09-24 21:55:45,716 Stage-30 map = 100%,  reduce = 0%, Cumulative CPU 35.0 sec
MapReduce Total cumulative CPU time: 35 seconds 0 msec
Ended Job = job_1474660851143_0429
Stage-41 is filtered out by condition resolver.
Stage-42 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Launching Job 3 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0430, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0430/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0430
Hadoop job information for Stage-3: number of mappers: 5; number of reducers: 2
2016-09-24 21:55:51,783 Stage-3 map = 0%,  reduce = 0%
2016-09-24 21:56:02,136 Stage-3 map = 3%,  reduce = 0%, Cumulative CPU 7.11 sec
2016-09-24 21:56:04,210 Stage-3 map = 77%,  reduce = 0%, Cumulative CPU 24.3 sec
2016-09-24 21:56:05,244 Stage-3 map = 87%,  reduce = 0%, Cumulative CPU 28.76 sec
2016-09-24 21:56:08,332 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 31.83 sec
2016-09-24 21:56:11,419 Stage-3 map = 93%,  reduce = 0%, Cumulative CPU 35.05 sec
2016-09-24 21:56:17,597 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 41.72 sec
2016-09-24 21:56:27,932 Stage-3 map = 100%,  reduce = 72%, Cumulative CPU 56.88 sec
2016-09-24 21:56:31,022 Stage-3 map = 100%,  reduce = 80%, Cumulative CPU 63.39 sec
2016-09-24 21:56:34,118 Stage-3 map = 100%,  reduce = 88%, Cumulative CPU 69.74 sec
2016-09-24 21:56:37,210 Stage-3 map = 100%,  reduce = 96%, Cumulative CPU 76.16 sec
2016-09-24 21:56:38,243 Stage-3 map = 100%,  reduce = 97%, Cumulative CPU 77.61 sec
2016-09-24 21:56:39,275 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 79.87 sec
MapReduce Total cumulative CPU time: 1 minutes 19 seconds 870 msec
Ended Job = job_1474660851143_0430
Stage-39 is filtered out by condition resolver.
Stage-40 is filtered out by condition resolver.
Stage-4 is selected by condition resolver.
Launching Job 4 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0431, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0431/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0431
Hadoop job information for Stage-4: number of mappers: 6; number of reducers: 2
2016-09-24 21:56:45,168 Stage-4 map = 0%,  reduce = 0%
2016-09-24 21:56:54,453 Stage-4 map = 17%,  reduce = 0%, Cumulative CPU 4.34 sec
2016-09-24 21:56:57,560 Stage-4 map = 67%,  reduce = 0%, Cumulative CPU 26.13 sec
2016-09-24 21:57:02,716 Stage-4 map = 78%,  reduce = 0%, Cumulative CPU 41.62 sec
2016-09-24 21:57:03,752 Stage-4 map = 83%,  reduce = 0%, Cumulative CPU 43.13 sec
2016-09-24 21:57:04,786 Stage-4 map = 94%,  reduce = 0%, Cumulative CPU 46.49 sec
2016-09-24 21:57:06,849 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 48.65 sec
2016-09-24 21:57:17,181 Stage-4 map = 100%,  reduce = 71%, Cumulative CPU 63.5 sec
2016-09-24 21:57:20,295 Stage-4 map = 100%,  reduce = 78%, Cumulative CPU 69.84 sec
2016-09-24 21:57:23,392 Stage-4 map = 100%,  reduce = 84%, Cumulative CPU 76.2 sec
2016-09-24 21:57:25,457 Stage-4 map = 100%,  reduce = 87%, Cumulative CPU 79.4 sec
2016-09-24 21:57:26,494 Stage-4 map = 100%,  reduce = 91%, Cumulative CPU 82.3 sec
2016-09-24 21:57:28,557 Stage-4 map = 100%,  reduce = 97%, Cumulative CPU 88.78 sec
2016-09-24 21:57:29,592 Stage-4 map = 100%,  reduce = 98%, Cumulative CPU 89.53 sec
2016-09-24 21:57:30,633 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 91.75 sec
MapReduce Total cumulative CPU time: 1 minutes 31 seconds 750 msec
Ended Job = job_1474660851143_0431
Stage-37 is filtered out by condition resolver.
Stage-38 is filtered out by condition resolver.
Stage-5 is selected by condition resolver.
Launching Job 5 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0432, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0432/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0432
Hadoop job information for Stage-5: number of mappers: 3; number of reducers: 2
2016-09-24 21:57:37,459 Stage-5 map = 0%,  reduce = 0%
2016-09-24 21:57:48,743 Stage-5 map = 33%,  reduce = 0%, Cumulative CPU 17.5 sec
2016-09-24 21:57:54,900 Stage-5 map = 68%,  reduce = 0%, Cumulative CPU 30.2 sec
2016-09-24 21:57:57,975 Stage-5 map = 78%,  reduce = 0%, Cumulative CPU 36.67 sec
2016-09-24 21:58:00,030 Stage-5 map = 89%,  reduce = 0%, Cumulative CPU 38.36 sec
2016-09-24 21:58:01,059 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 41.07 sec
2016-09-24 21:58:11,324 Stage-5 map = 100%,  reduce = 69%, Cumulative CPU 51.77 sec
2016-09-24 21:58:14,403 Stage-5 map = 100%,  reduce = 76%, Cumulative CPU 58.44 sec
2016-09-24 21:58:17,486 Stage-5 map = 100%,  reduce = 82%, Cumulative CPU 64.85 sec
2016-09-24 21:58:20,572 Stage-5 map = 100%,  reduce = 89%, Cumulative CPU 71.48 sec
2016-09-24 21:58:23,654 Stage-5 map = 100%,  reduce = 96%, Cumulative CPU 77.91 sec
2016-09-24 21:58:25,712 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 82.28 sec
MapReduce Total cumulative CPU time: 1 minutes 22 seconds 280 msec
Ended Job = job_1474660851143_0432
Stage-35 is selected by condition resolver.
Stage-36 is filtered out by condition resolver.
Stage-6 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924215340_e48ea5f2-4ab3-44ea-bbbe-9345dde5a1df.log
2016-09-24 21:58:30	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:58:32	Dump the side-table for tag: 1 with group count: 365 into file: file:/tmp/ubuntu/48fb8276-5285-4c43-992a-c9d4a1b1b697/hive_2016-09-24_21-53-40_195_1030987788315948952-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable
2016-09-24 21:58:32	Uploaded 1 File to: file:/tmp/ubuntu/48fb8276-5285-4c43-992a-c9d4a1b1b697/hive_2016-09-24_21-53-40_195_1030987788315948952-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable (7963 bytes)
2016-09-24 21:58:32	End of local task; Time Taken: 2.392 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 7 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474660851143_0433, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0433/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0433
Hadoop job information for Stage-18: number of mappers: 2; number of reducers: 0
2016-09-24 21:58:38,362 Stage-18 map = 0%,  reduce = 0%
2016-09-24 21:58:52,760 Stage-18 map = 64%,  reduce = 0%, Cumulative CPU 20.87 sec
2016-09-24 21:58:53,794 Stage-18 map = 100%,  reduce = 0%, Cumulative CPU 21.62 sec
MapReduce Total cumulative CPU time: 21 seconds 620 msec
Ended Job = job_1474660851143_0433
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20160924215340_e48ea5f2-4ab3-44ea-bbbe-9345dde5a1df.log
2016-09-24 21:58:57	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-24 21:58:58	Dump the side-table for tag: 1 with group count: 39 into file: file:/tmp/ubuntu/48fb8276-5285-4c43-992a-c9d4a1b1b697/hive_2016-09-24_21-53-40_195_1030987788315948952-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable
2016-09-24 21:58:58	Uploaded 1 File to: file:/tmp/ubuntu/48fb8276-5285-4c43-992a-c9d4a1b1b697/hive_2016-09-24_21-53-40_195_1030987788315948952-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (1662 bytes)
2016-09-24 21:58:58	End of local task; Time Taken: 1.208 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 8 out of 16
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0434, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0434/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0434
Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1
2016-09-24 21:59:04,359 Stage-8 map = 0%,  reduce = 0%
2016-09-24 21:59:14,632 Stage-8 map = 33%,  reduce = 0%, Cumulative CPU 7.3 sec
2016-09-24 21:59:16,694 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 8.9 sec
2016-09-24 21:59:22,863 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 10.56 sec
MapReduce Total cumulative CPU time: 10 seconds 560 msec
Ended Job = job_1474660851143_0434
Launching Job 9 out of 16
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474660851143_0435, Tracking URL = http://vm1:8088/proxy/application_1474660851143_0435/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474660851143_0435
Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 1
2016-09-24 21:59:28,853 Stage-9 map = 0%,  reduce = 0%
2016-09-24 21:59:34,013 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 1.18 sec
2016-09-24 21:59:40,199 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 2.65 sec
MapReduce Total cumulative CPU time: 2 seconds 650 msec
Ended Job = job_1474660851143_0435
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 30  Reduce: 32   Cumulative CPU: 539.66 sec   HDFS Read: 8124263543 HDFS Write: 226967742 SUCCESS
Stage-Stage-30: Map: 4   Cumulative CPU: 35.0 sec   HDFS Read: 227005674 HDFS Write: 235481511 SUCCESS
Stage-Stage-3: Map: 5  Reduce: 2   Cumulative CPU: 79.87 sec   HDFS Read: 316193629 HDFS Write: 293830122 SUCCESS
Stage-Stage-4: Map: 6  Reduce: 2   Cumulative CPU: 91.75 sec   HDFS Read: 374557569 HDFS Write: 348836512 SUCCESS
Stage-Stage-5: Map: 3  Reduce: 2   Cumulative CPU: 82.28 sec   HDFS Read: 391387923 HDFS Write: 419920313 SUCCESS
Stage-Stage-18: Map: 2   Cumulative CPU: 21.62 sec   HDFS Read: 419945497 HDFS Write: 85556527 SUCCESS
Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 10.56 sec   HDFS Read: 85590129 HDFS Write: 1858 SUCCESS
Stage-Stage-9: Map: 1  Reduce: 1   Cumulative CPU: 2.65 sec   HDFS Read: 7071 HDFS Write: 1783 SUCCESS
Total MapReduce CPU Time Spent: 14 minutes 23 seconds 390 msec
OK
Did not fit	36.4	922.3180053710937	44.14999961853027
Did not like the col	7.0	65.66000366210938	52.52000045776367
Did not like the mak	12.0	359.4599914550781	34.9900016784668
Did not like the mod	4.5	96.23500061035156	18.535000205039978
Found a better exten	5.0	65.47000122070312	41.73500061035156
Found a better price	21.5	365.5500011444092	44.73249959945679
Gift exchange	15.5	502.5549907684326	48.635000228881836
No service location 	18.0	670.0650100708008	32.06499934196472
Not working any more	22.0	90.98999977111816	20.105000019073486
Package was damaged	19.0	941.0019750595093	31.7440003156662
Parts missing	14.333333333333334	213.90000025431314	57.020002365112305
Stopped working	27.0	452.43249130249023	70.0649995803833
Wrong size	23.5	431.12999725341797	65.73999786376953
duplicate purchase	18.0	0.0	5.519999980926514
it is a girl	10.5	474.72498321533203	29.644999027252197
its is a boy	27.5	196.35500717163086	26.50499999523163
reason 24	9.75	172.76999378204346	65.16749954223633
reason 25	9.0	259.3500061035156	52.0099983215332
reason 26	5.0	248.11000061035156	74.68000030517578
reason 27	25.666666666666668	467.3833363850911	38.336666107177734
reason 28	42.0	497.6000061035156	64.03499984741211
reason 29	22.0	374.82666810353595	44.30666542053223
reason 31	36.25	760.8725032806396	54.20750141143799
reason 32	44.0	92.88000297546387	75.44499969482422
reason 33	9.0	180.9300038019816	45.070000330607094
reason 34	31.0	263.83998918533325	33.27000069618225
reason 35	6.0	558.7899780273438	70.2300033569336
reason 36	14.0	407.8599853515625	67.08999633789062
reason 37	24.0	526.3600006103516	57.30000114440918
reason 38	9.0	146.94749927520752	21.157500505447388
reason 39	52.5	675.9999961853027	43.98499870300293
unauthoized purchase	37.0	761.5599975585938	43.720001220703125
Time taken: 362.147 seconds, Fetched: 32 row(s)
Query 85: Total Execution Time = 370 seconds
